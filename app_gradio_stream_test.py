"""Gradio é¡µé¢ï¼š16 kHz å½•éŸ³ â†’ å¬æ‚Ÿ WebSocket æ¨æµ â†’ å®æ—¶å­—å¹•."""

from __future__ import annotations

import asyncio
import contextlib
import json
import math
import uuid
from dataclasses import dataclass
from typing import AsyncGenerator, Optional

import gradio as gr
import numpy as np
import websockets

from packages.common.config import settings
from services.audio.tingwu_client import create_realtime_task, stop_realtime_task


@dataclass(slots=True)
class TingwuStreamConfig:
    """Normalized Tingwu realtime streaming configuration."""

    appkey: str
    format: str
    language: str
    sample_rate: int
    frame_ms: int = 40

    @property
    def frame_bytes(self) -> int:
        """Number of bytes per PCM frame according to configured frame size."""

        samples_per_frame = max(int(self.sample_rate * self.frame_ms / 1000), 1)
        return samples_per_frame * 2  # 16-bit mono PCM


def _build_config() -> TingwuStreamConfig:
    appkey = settings.TINGWU_APPKEY or settings.ALIBABA_TINGWU_APPKEY
    if not appkey:
        raise RuntimeError("è¯·åœ¨ .env ä¸­é…ç½® TINGWU_APPKEY æˆ– ALIBABA_TINGWU_APPKEY")

    return TingwuStreamConfig(
        appkey=appkey,
        format=settings.TINGWU_FORMAT or "pcm",
        language=settings.TINGWU_LANG or "cn",
        sample_rate=settings.TINGWU_SAMPLE_RATE or 16000,
    )


def _ensure_mono(audio_data: np.ndarray) -> np.ndarray:
    if audio_data.ndim == 1:
        return audio_data
    return np.mean(audio_data, axis=1)


def _resample_if_needed(audio_data: np.ndarray, original_sr: int, target_sr: int) -> np.ndarray:
    if original_sr == target_sr:
        return audio_data
    duration = audio_data.shape[0] / float(original_sr)
    target_samples = max(int(math.ceil(duration * target_sr)), 1)
    source_times = np.linspace(0.0, duration, num=audio_data.shape[0], endpoint=False)
    target_times = np.linspace(0.0, duration, num=target_samples, endpoint=False)
    return np.interp(target_times, source_times, audio_data).astype(np.float32)


def _pcm_bytes(audio_data: np.ndarray) -> bytes:
    normalized = np.clip(audio_data, -1.0, 1.0)
    return (normalized * 32767).astype("<i2").tobytes()


def _extract_text(payload: dict) -> Optional[str]:
    for key in ("display_text", "text", "result"):
        value = payload.get(key)
        if isinstance(value, str) and value.strip():
            return value.strip()
    return None


async def stream_audio_to_tingwu(
    audio_data: np.ndarray, sample_rate: int, queue: asyncio.Queue[str]
) -> None:
    """æ¨é€éŸ³é¢‘åˆ° Tingwu å¹¶å®æ—¶æ¥æ”¶è¯†åˆ«ç»“æœ."""

    cfg = _build_config()
    mono_audio = _ensure_mono(audio_data.astype(np.float32))
    processed_audio = _resample_if_needed(mono_audio, sample_rate, cfg.sample_rate)
    pcm_bytes = _pcm_bytes(processed_audio)

    try:
        ws_url, task_id = await asyncio.to_thread(create_realtime_task)
    except Exception as exc:  # pylint: disable=broad-except
        await queue.put(f"âŒ åˆ›å»ºå¬æ‚Ÿå®æ—¶ä»»åŠ¡å¤±è´¥: {exc}")
        return

    start_message = {
        "header": {
            "namespace": "SpeechTranscription",
            "name": "StartTranscription",
            "appkey": cfg.appkey,
            "message_id": str(uuid.uuid4()),
            "task_id": task_id,
        },
        "payload": {
            "format": cfg.format,
            "sample_rate": cfg.sample_rate,
            "language": cfg.language,
            "enable_intermediate_result": True,
            "enable_punctuation_prediction": True,
            "enable_inverse_text_normalization": True,
            "enable_semantic_sentence_detection": True,
        },
    }
    stop_message = {
        "header": {
            "namespace": "SpeechTranscription",
            "name": "StopTranscription",
            "appkey": cfg.appkey,
            "message_id": str(uuid.uuid4()),
            "task_id": task_id,
        }
    }

    async def receive_results(ws):  # type: ignore[no-untyped-def]
        try:
            async for raw in ws:
                if isinstance(raw, bytes):
                    continue
                try:
                    message = json.loads(raw)
                except json.JSONDecodeError:
                    continue
                header = message.get("header", {})
                payload = message.get("payload", {})
                status = header.get("status")
                if isinstance(status, int) and status >= 40000000:
                    detail = payload.get("message") or payload.get("error_message")
                    await queue.put(
                        f"âš ï¸ å¬æ‚Ÿè¿”å›é”™è¯¯({status}): {detail or json.dumps(payload, ensure_ascii=False)}"
                    )
                    continue
                text = _extract_text(payload)
                if not text:
                    continue
                name = (header.get("name") or "").lower()
                prefix = "å®æ—¶è¯†åˆ«"
                if "sentenceend" in name or "completed" in name or "result" in name:
                    prefix = "æœ€ç»ˆç»“æœ"
                await queue.put(f"{prefix}: {text}")
        except Exception as exc:  # pylint: disable=broad-except
            await queue.put(f"âš ï¸ WebSocket ç›‘å¬ä¸­æ–­: {exc}")

    try:
        async with websockets.connect(ws_url, ping_interval=10) as ws:
            await queue.put(f"âœ… å·²è¿æ¥å¬æ‚Ÿå®æ—¶ä»»åŠ¡ï¼ˆTaskId: {task_id}ï¼‰")
            await ws.send(json.dumps(start_message, ensure_ascii=False))

            receiver = asyncio.create_task(receive_results(ws))
            frame_bytes = max(cfg.frame_bytes, 640)
            for idx in range(0, len(pcm_bytes), frame_bytes):
                await ws.send(pcm_bytes[idx : idx + frame_bytes])
                await asyncio.sleep(cfg.frame_ms / 1000.0)

            await ws.send(json.dumps(stop_message, ensure_ascii=False))
            await queue.put("ğŸ›‘ éŸ³é¢‘æ¨æµå®Œæˆï¼Œç­‰å¾…è¯†åˆ«æ”¶å°¾...")
            await receiver
    except Exception as exc:  # pylint: disable=broad-except
        await queue.put(f"âŒ æ¨æµå¤±è´¥: {exc}")
    finally:
        await asyncio.to_thread(stop_realtime_task, task_id)


def start_realtime_stream(audio: Optional[tuple[int, np.ndarray]]) -> AsyncGenerator[str, None]:
    """å½•éŸ³å›è°ƒï¼Œå®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ."""

    if audio is None:

        async def no_audio() -> AsyncGenerator[str, None]:
            yield "æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥"

        return no_audio()

    sample_rate, data = audio
    queue: "asyncio.Queue[str]" = asyncio.Queue()

    async def run_stream() -> None:
        await stream_audio_to_tingwu(data, sample_rate, queue)
        await queue.put("âœ… æµç¨‹ç»“æŸ")

    async def update_output() -> AsyncGenerator[str, None]:
        task = asyncio.create_task(run_stream())
        try:
            while True:
                text = await queue.get()
                yield text
                if any(keyword in text for keyword in ("æµç¨‹ç»“æŸ", "å¤±è´¥", "ä¸­æ–­")):
                    break
        finally:
            if not task.done():
                task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await task

    return update_output()


with gr.Blocks() as demo:
    gr.Markdown("## ğŸ§ å¬æ‚Ÿå®æ—¶è¯­éŸ³è¯†åˆ« (16 kHz å•å£°é“, å®æ—¶å­—å¹•)")
    mic = gr.Audio(
        sources=["microphone"],
        type="numpy",
        streaming=True,
        label="ğŸ™ï¸ éº¦å…‹é£è¾“å…¥ (16 kHz å•å£°é“)",
    )
    output = gr.Textbox(label="å®æ—¶è¯†åˆ«ç»“æœ", lines=6)
    mic.stream(fn=start_realtime_stream, inputs=mic, outputs=output)


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=8001)
