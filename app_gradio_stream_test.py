"""Gradio é¡µé¢ï¼š16 kHz å½•éŸ³ â†’ å¬æ‚Ÿ WebSocket æ¨æµ â†’ å®æ—¶å­—å¹•."""

from __future__ import annotations

import asyncio
import contextlib
import json
from dataclasses import dataclass
from typing import AsyncGenerator, Optional

import gradio as gr
import numpy as np
import websockets

from packages.common.config import settings
from services.audio.tingwu_async_client import (
    create_realtime_task,
    stop_realtime_task,
)


@dataclass(slots=True)
class TingwuStreamConfig:
    """Normalized Tingwu realtime streaming configuration."""

    appkey: str
    format: str
    language: str
    sample_rate: int
    frame_ms: int = 40

    @property
    def frame_bytes(self) -> int:
        """Number of bytes per PCM frame according to configured frame size."""

        samples_per_frame = max(int(self.sample_rate * self.frame_ms / 1000), 1)
        return samples_per_frame * 2  # 16-bit mono PCM


def _build_config() -> TingwuStreamConfig:
    appkey = settings.TINGWU_APPKEY or settings.ALIBABA_TINGWU_APPKEY
    if not appkey:
        raise RuntimeError("è¯·åœ¨ .env ä¸­é…ç½® TINGWU_APPKEY æˆ– ALIBABA_TINGWU_APPKEY")

    return TingwuStreamConfig(
        appkey=appkey,
        format=settings.TINGWU_FORMAT or "pcm",
        language=settings.TINGWU_LANG or "cn",
        sample_rate=16000,
    )


def _ensure_mono(audio_data: np.ndarray) -> np.ndarray:
    if audio_data.ndim == 1:
        return audio_data
    return np.mean(audio_data, axis=1)


def _resample_if_needed(audio_data: np.ndarray, original_sr: int, target_sr: int) -> np.ndarray:
    if original_sr == target_sr:
        return audio_data
    if audio_data.size == 0:
        return audio_data
    original_indices = np.arange(audio_data.shape[0], dtype=np.float32)
    target_length = max(int(round(audio_data.shape[0] * target_sr / original_sr)), 1)
    target_indices = np.linspace(0, original_indices[-1], num=target_length, dtype=np.float32)
    return np.interp(target_indices, original_indices, audio_data).astype(np.float32)


def _pcm_bytes(audio_data: np.ndarray) -> bytes:
    normalized = np.clip(audio_data, -1.0, 1.0)
    return (normalized * 32767).astype("<i2").tobytes()


async def stream_audio_to_tingwu(
    audio_data: np.ndarray, sample_rate: int, queue: asyncio.Queue[str]
) -> None:
    """æ¨é€éŸ³é¢‘åˆ° Tingwu å¹¶å®æ—¶æ¥æ”¶è¯†åˆ«ç»“æœ."""

    cfg = _build_config()
    mono_audio = _ensure_mono(audio_data.astype(np.float32))
    processed_audio = _resample_if_needed(mono_audio, sample_rate, cfg.sample_rate)
    pcm_bytes = _pcm_bytes(processed_audio)

    try:
        ws_url, task_id = await create_realtime_task()
    except Exception as exc:  # pylint: disable=broad-except
        await queue.put(f"âŒ åˆ›å»ºå¬æ‚Ÿå®æ—¶ä»»åŠ¡å¤±è´¥: {exc}")
        return

    print(f"âœ… ä»»åŠ¡å·²åˆ›å»º ({task_id})", flush=True)
    await queue.put(f"âœ… ä»»åŠ¡å·²åˆ›å»º ({task_id})")

    start_message = {
        "header": {
            "namespace": "SpeechTranscriber",
            "name": "StartTranscription",
        },
        "payload": {
            "format": cfg.format,
            "sample_rate": cfg.sample_rate,
            "language": cfg.language,
            "enable_punctuation_prediction": True,
            "enable_inverse_text_normalization": True,
            "enable_semantic_sentence_detection": True,
        },
    }
    stop_message = {
        "header": {
            "namespace": "SpeechTranscriber",
            "name": "StopTranscription",
        }
    }

    async def receive_results(ws):  # type: ignore[no-untyped-def]
        try:
            async for raw in ws:
                if isinstance(raw, bytes):
                    continue
                try:
                    message = json.loads(raw)
                except json.JSONDecodeError:
                    continue
                header = message.get("header", {})
                payload = message.get("payload", {})
                name = header.get("name")
                if name:
                    print(f"ğŸ“¥ æ”¶åˆ°æ¶ˆæ¯ {name}", flush=True)
                status = header.get("status")
                if isinstance(status, int) and status >= 40000000:
                    detail = payload.get("message") or payload.get("error_message")
                    await queue.put(
                        f"âš ï¸ å¬æ‚Ÿè¿”å›é”™è¯¯({status}): {detail or json.dumps(payload, ensure_ascii=False)}"
                    )
                    continue
                text = None
                if isinstance(payload, dict):
                    if isinstance(payload.get("result"), str) and payload["result"].strip():
                        text = payload["result"].strip()
                    elif isinstance(payload.get("text"), str) and payload["text"].strip():
                        text = payload["text"].strip()
                if text:
                    await queue.put(f"ğŸ“ å®æ—¶è¯†åˆ«ç»“æœï¼š{text}")
        except Exception as exc:  # pylint: disable=broad-except
            await queue.put(f"âš ï¸ WebSocket ç›‘å¬ä¸­æ–­: {exc}")

    try:
        async with websockets.connect(ws_url, ping_interval=10) as ws:
            await queue.put("âœ… WebSocket å·²è¿æ¥")
            await ws.send(json.dumps(start_message, ensure_ascii=False))

            receiver = asyncio.create_task(receive_results(ws))
            frame_size = 640
            total_frames = (len(pcm_bytes) + frame_size - 1) // frame_size
            for frame_index in range(total_frames):
                start = frame_index * frame_size
                await ws.send(pcm_bytes[start : start + frame_size])
                print(f"ğŸ“¤ å·²å‘é€ç¬¬ {frame_index + 1} å¸§", flush=True)
                await asyncio.sleep(0.01)

            await ws.send(json.dumps(stop_message, ensure_ascii=False))
            print("ğŸ”š Stop æŒ‡ä»¤å·²å‘é€ï¼Œç­‰å¾… 3 ç§’åå…³é—­", flush=True)
            await asyncio.sleep(3)
            print("ğŸ”š Stop å®Œæˆå¹¶å…³é—­ WebSocket", flush=True)
            await ws.close()

            if not receiver.done():
                receiver.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await receiver
            await queue.put("ğŸ”š Stop å®Œæˆå¹¶å…³é—­ WebSocket")
    except Exception as exc:  # pylint: disable=broad-except
        await queue.put(f"âŒ æ¨æµå¤±è´¥: {exc}")
    finally:
        try:
            await stop_realtime_task(task_id)
        except Exception as exc:  # pylint: disable=broad-except
            print(f"âš ï¸ åœæ­¢å®æ—¶ä»»åŠ¡å¤±è´¥: {exc}", flush=True)


def start_realtime_stream(audio: Optional[tuple[int, np.ndarray]]) -> AsyncGenerator[str, None]:
    """å½•éŸ³å›è°ƒï¼Œå®æ—¶æ˜¾ç¤ºè¯†åˆ«ç»“æœ."""

    if audio is None:

        async def no_audio() -> AsyncGenerator[str, None]:
            yield "æœªæ£€æµ‹åˆ°éŸ³é¢‘è¾“å…¥"

        return no_audio()

    sample_rate, data = audio
    queue: "asyncio.Queue[str]" = asyncio.Queue()

    async def run_stream() -> None:
        await stream_audio_to_tingwu(data, sample_rate, queue)
        await queue.put("âœ… æµç¨‹ç»“æŸ")

    async def update_output() -> AsyncGenerator[str, None]:
        task = asyncio.create_task(run_stream())
        try:
            while True:
                text = await queue.get()
                yield text
                if any(keyword in text for keyword in ("æµç¨‹ç»“æŸ", "å¤±è´¥", "ä¸­æ–­")):
                    break
        finally:
            if not task.done():
                task.cancel()
                with contextlib.suppress(asyncio.CancelledError):
                    await task

    return update_output()


with gr.Blocks() as demo:
    gr.Markdown("## ğŸ§ å¬æ‚Ÿå®æ—¶è¯­éŸ³è¯†åˆ« (16 kHz å•å£°é“, å®æ—¶å­—å¹•)")
    mic = gr.Audio(
        sources=["microphone"],
        type="numpy",
        streaming=True,
        label="ğŸ™ï¸ éº¦å…‹é£è¾“å…¥ (16 kHz å•å£°é“)",
    )
    output = gr.Textbox(label="å®æ—¶è¯†åˆ«ç»“æœ", lines=6)
    mic.stream(fn=start_realtime_stream, inputs=mic, outputs=output)


if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=8001)
