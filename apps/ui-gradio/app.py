from __future__ import annotations

import asyncio
import contextlib
import json
import os
import sys
import uuid
from pathlib import Path
from typing import Any, AsyncGenerator, Dict, List, Optional, Tuple


PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import gradio as gr
import numpy as np
import requests
import websockets

from services.audio.tingwu_async_client import (
    create_realtime_task,
    stop_realtime_task,
)

API_BASE = (
    os.getenv("DM_API_BASE", os.getenv("API_BASE_URL", "http://localhost:8080"))
    or "http://localhost:8080"
).rstrip("/")


TARGET_SAMPLE_RATE = 16_000
FRAME_DURATION_SECONDS = 0.02  # 20 ms per frame
PCM_BYTES_PER_SAMPLE = 2  # int16 mono
FRAME_BYTE_LENGTH = int(TARGET_SAMPLE_RATE * FRAME_DURATION_SECONDS) * PCM_BYTES_PER_SAMPLE
CREATE_TASK_MAX_RETRIES = 3
CONNECT_MAX_RETRIES = 3
CONNECT_BACKOFF_SECONDS = 1.5
PING_INTERVAL_SECONDS = 15


def _init_session() -> str:
    return str(uuid.uuid4())


def _call_dm_step(
    sid: str, text: Optional[str] = None, audio_ref: Optional[str] = None
) -> Dict[str, Any]:
    payload: Dict[str, Any] = {"sid": sid}
    if text:
        payload["text"] = text
    if audio_ref:
        payload["audio_ref"] = audio_ref

    response = requests.post(f"{API_BASE}/dm/step", json=payload, timeout=30)
    response.raise_for_status()
    return response.json()


def _upload_audio(sid: str, file_path: str) -> str:
    url = f"{API_BASE}/upload/audio"
    file_name = Path(file_path).name or "audio.wav"
    with open(file_path, "rb") as handle:
        files = {"file": (file_name, handle, "application/octet-stream")}
        data = {"sid": sid}
        response = requests.post(url, files=files, data=data, timeout=60)
    response.raise_for_status()
    payload = response.json()
    audio_ref = payload.get("audio_ref")
    if not audio_ref:
        raise ValueError("audio_ref missing in upload response")
    return audio_ref


def _generate_report(session_id: str) -> str:
    try:
        resp = requests.post(
            f"{API_BASE}/report/build", json={"sid": session_id}, timeout=60
        )
        resp.raise_for_status()
        data = resp.json()
        url = data.get("report_url")
        if url:
            return f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{url}"
        return "âš ï¸ æŠ¥å‘Šç”ŸæˆæˆåŠŸä½†æœªè¿”å›žé“¾æŽ¥ã€‚"
    except Exception as exc:  # noqa: BLE001 - surface to UI
        return f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{exc}"


def user_step(
    message: str,
    audio_path: Optional[str],
    history: List[Tuple[str, str]],
    session_id: str,
) -> Tuple[List[Tuple[str, str]], str, Dict[str, Any], str, Optional[str]]:
    message = message or ""
    text_payload = message.strip() or None
    audio_ref: Optional[str] = None
    risk_text = "æ— ç´§æ€¥é£Žé™©æç¤ºã€‚"
    progress: Dict[str, Any] = {}
    audio_value: Optional[str] = None

    try:
        if audio_path:
            audio_ref = _upload_audio(session_id, audio_path)
            if not text_payload:
                text_payload = None

        result = _call_dm_step(session_id, text=text_payload, audio_ref=audio_ref)
    except Exception as exc:  # noqa: BLE001 - surface API failures to the UI
        if text_payload:
            user_label = message
        elif audio_path:
            user_label = f"[éŸ³é¢‘] {Path(audio_path).name}"
        else:
            user_label = "[ç©ºè¾“å…¥]"

        history = history + [(user_label, f"âŒ è¯·æ±‚å¤±è´¥ï¼š{exc}")]
        return history, "âš ï¸ è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åŽé‡è¯•ã€‚", {}, session_id, None

    assistant_reply = result.get("next_utterance", "")
    previews = result.get("segments_previews") or []
    tts_url = result.get("tts_url")
    if tts_url:
        if tts_url.startswith("file://"):
            local_path = tts_url[7:]
            if Path(local_path).exists():
                audio_value = local_path
        else:
            audio_value = tts_url

    if previews:
        recent_previews = previews[-2:]
        preview_text = "\n".join(f"- {item}" for item in recent_previews if item)
        if preview_text:
            assistant_reply = f"{assistant_reply}\n\n_æœ€è¿‘è½¬å†™é¢„è§ˆ_:\n{preview_text}"

    user_label: Optional[str] = None
    if text_payload:
        user_label = message
    elif audio_path:
        user_label = f"[éŸ³é¢‘] {Path(audio_path).name}"

    if user_label:
        history = history + [(user_label, assistant_reply)]
    else:
        history = history + [(None, assistant_reply)]

    progress = result.get("progress", {})
    risk_flag = result.get("risk_flag", False)
    risk_text = (
        "âš ï¸ æ£€æµ‹åˆ°é«˜é£Žé™©ï¼Œè¯·ç«‹å³å¯»æ±‚ç´§æ€¥å¸®åŠ©ã€‚" if risk_flag else "æ— ç´§æ€¥é£Žé™©æç¤ºã€‚"
    )

    return history, risk_text, progress, session_id, audio_value


def _ensure_mono(audio: np.ndarray) -> np.ndarray:
    if audio.ndim == 1:
        return audio
    return np.mean(audio, axis=1)


def _resample_audio(audio: np.ndarray, source_rate: int) -> np.ndarray:
    if source_rate == TARGET_SAMPLE_RATE:
        return audio
    if source_rate <= 0 or audio.size == 0:
        return np.asarray([], dtype=np.float32)

    duration = audio.shape[0] / float(source_rate)
    target_length = max(int(round(duration * TARGET_SAMPLE_RATE)), 1)
    source_positions = np.linspace(0.0, duration, num=audio.shape[0], endpoint=False)
    target_positions = np.linspace(0.0, duration, num=target_length, endpoint=False)
    resampled = np.interp(target_positions, source_positions, audio)
    return resampled.astype(np.float32)


def _to_pcm(audio: np.ndarray) -> bytes:
    if audio.size == 0:
        return b""
    clipped = np.clip(audio, -1.0, 1.0)
    pcm = (clipped * np.iinfo(np.int16).max).astype("<i2")
    return pcm.tobytes()


def _iter_frames(pcm_bytes: bytes) -> List[bytes]:
    if not pcm_bytes:
        return []
    frames: List[bytes] = []
    for offset in range(0, len(pcm_bytes), FRAME_BYTE_LENGTH):
        frame = pcm_bytes[offset : offset + FRAME_BYTE_LENGTH]
        if len(frame) < FRAME_BYTE_LENGTH:
            frame = frame + b"\x00" * (FRAME_BYTE_LENGTH - len(frame))
        frames.append(frame)
    return frames


def _extract_text(payload: Dict[str, Any]) -> Optional[str]:
    if not isinstance(payload, dict):
        return None
    result = payload.get("result")
    if isinstance(result, str) and result.strip():
        return result.strip()
    if isinstance(result, dict):
        text = result.get("text")
        if isinstance(text, str) and text.strip():
            return text.strip()
    if isinstance(payload.get("text"), str) and payload["text"].strip():
        return payload["text"].strip()
    return None


async def _stream_realtime_audio(
    sample_rate: int,
    audio_data: np.ndarray,
    queue: "asyncio.Queue[object]",
) -> None:
    audio_data = audio_data.astype(np.float32)
    mono_audio = _ensure_mono(audio_data)
    resampled = _resample_audio(mono_audio, sample_rate)
    if resampled.size == 0:
        await queue.put("âš ï¸ æœªæ£€æµ‹åˆ°æœ‰æ•ˆçš„éŸ³é¢‘æ ·æœ¬ã€‚")
        return

    pcm_bytes = _to_pcm(resampled)
    frames = _iter_frames(pcm_bytes)
    await queue.put(
        "ðŸŽ™ï¸ éŸ³é¢‘å¤„ç†å®Œæˆï¼Œå‡†å¤‡æŽ¨æµï¼š"
        f"{len(resampled)} ä¸ªæ ·æœ¬ï¼Œæ‹†åˆ†ä¸º {len(frames)} å¸§ã€‚"
    )

    task_id: Optional[str] = None
    ws_url: Optional[str] = None
    for attempt in range(1, CREATE_TASK_MAX_RETRIES + 1):
        try:
            ws_url, task_id = await create_realtime_task()
            await queue.put(f"âœ… å·²åˆ›å»ºå®žæ—¶ä»»åŠ¡ï¼Œç¬¬ {attempt} æ¬¡å°è¯•æˆåŠŸã€‚")
            break
        except Exception as exc:  # pragma: no cover - network failure path
            await queue.put(
                f"âŒ åˆ›å»ºå®žæ—¶ä»»åŠ¡å¤±è´¥ï¼ˆç¬¬ {attempt} æ¬¡ï¼‰ï¼š{exc}"
            )
            if attempt == CREATE_TASK_MAX_RETRIES:
                return
            await asyncio.sleep(attempt * 0.5)

    if not ws_url or not task_id:
        await queue.put("âŒ æœªèƒ½èŽ·å¾—æœ‰æ•ˆçš„ WebSocket åœ°å€æˆ–ä»»åŠ¡ IDã€‚")
        return

    async def _cleanup_task() -> None:
        if not task_id:
            return
        with contextlib.suppress(Exception):
            await stop_realtime_task(task_id)

    try:
        backoff = CONNECT_BACKOFF_SECONDS
        for attempt in range(1, CONNECT_MAX_RETRIES + 1):
            try:
                await queue.put(
                    f"ðŸ”Œ æ­£åœ¨è¿žæŽ¥ WebSocketï¼ˆå°è¯• {attempt}/{CONNECT_MAX_RETRIES}ï¼‰â€¦"
                )
                async with websockets.connect(
                    ws_url,
                    ping_interval=None,
                    close_timeout=5,
                ) as ws:
                    await queue.put("âœ… WebSocket è¿žæŽ¥æˆåŠŸï¼Œå¼€å§‹æŽ¨æµã€‚")

                    async def send_loop() -> None:
                        try:
                            for index, frame in enumerate(frames, start=1):
                                await ws.send(frame)
                                if index % 10 == 0 or index == len(frames):
                                    await queue.put(
                                        f"ðŸ“¤ å·²å‘é€ {index}/{len(frames)} å¸§ã€‚"
                                    )
                                await asyncio.sleep(FRAME_DURATION_SECONDS)
                            await queue.put("ðŸ›‘ æ‰€æœ‰éŸ³é¢‘å¸§å·²å‘é€ï¼Œå‘é€åœæ­¢æŒ‡ä»¤ã€‚")
                            await ws.send(json.dumps({"action": "Stop"}))
                        except Exception as exc:  # pragma: no cover
                            await queue.put(f"âš ï¸ å‘é€éŸ³é¢‘æ•°æ®å¼‚å¸¸ï¼š{exc}")
                            raise

                    async def recv_loop() -> None:
                        try:
                            async for raw_msg in ws:
                                if isinstance(raw_msg, bytes):
                                    continue
                                try:
                                    message = json.loads(raw_msg)
                                except json.JSONDecodeError:
                                    await queue.put(
                                        "âš ï¸ æ”¶åˆ°æ— æ³•è§£æžçš„æ¶ˆæ¯ï¼Œå·²å¿½ç•¥ã€‚"
                                    )
                                    continue
                                header = message.get("header", {})
                                payload = message.get("payload", {})
                                name = header.get("name")
                                if isinstance(name, str):
                                    await queue.put(f"ðŸ“¥ æ”¶åˆ°äº‹ä»¶ï¼š{name}")
                                text = _extract_text(payload)
                                if text:
                                    await queue.put(f"ðŸ“ å®žæ—¶è¯†åˆ«ï¼š{text}")
                        except websockets.ConnectionClosedOK:
                            await queue.put("ðŸ”š WebSocket æ­£å¸¸å…³é—­ã€‚")
                        except Exception as exc:  # pragma: no cover
                            await queue.put(f"âš ï¸ æŽ¥æ”¶è¯†åˆ«ç»“æžœå¼‚å¸¸ï¼š{exc}")
                            raise

                    async def heartbeat_loop() -> None:
                        try:
                            while True:
                                await asyncio.sleep(PING_INTERVAL_SECONDS)
                                await ws.ping()
                        except asyncio.CancelledError:
                            raise
                        except Exception:
                            return

                    send_task = asyncio.create_task(send_loop())
                    recv_task = asyncio.create_task(recv_loop())
                    heartbeat_task = asyncio.create_task(heartbeat_loop())

                    done, pending = await asyncio.wait(
                        {send_task, recv_task},
                        return_when=asyncio.FIRST_COMPLETED,
                    )
                    for task in pending:
                        task.cancel()
                    heartbeat_task.cancel()
                    with contextlib.suppress(Exception):
                        await asyncio.gather(*pending, return_exceptions=True)
                    with contextlib.suppress(Exception):
                        await heartbeat_task
                    for task in done:
                        exc = task.exception()
                        if exc:
                            raise exc
                    break
            except Exception as exc:  # pragma: no cover - connection failure
                await queue.put(f"âŒ WebSocket è¿žæŽ¥å¤±è´¥ï¼š{exc}")
                if attempt == CONNECT_MAX_RETRIES:
                    raise
                await asyncio.sleep(backoff)
                backoff *= 2
    finally:
        with contextlib.suppress(Exception):
            await _cleanup_task()
        await queue.put("âœ… å®žæ—¶ä»»åŠ¡å·²ç»“æŸã€‚")


async def realtime_stream_to_frontend(
    audio: Optional[Tuple[int, np.ndarray]]
) -> AsyncGenerator[str, None]:
    if not audio:
        yield "âš ï¸ æœªæŽ¥æ”¶åˆ°éº¦å…‹é£ŽéŸ³é¢‘ã€‚"
        return

    sample_rate, data = audio
    if data is None or getattr(data, "size", 0) == 0:
        yield "âš ï¸ éŸ³é¢‘æ•°æ®ä¸ºç©ºã€‚"
        return

    queue: "asyncio.Queue[object]" = asyncio.Queue()
    sentinel = object()

    async def runner() -> None:
        try:
            await _stream_realtime_audio(sample_rate, data, queue)
        finally:
            await queue.put(sentinel)

    worker = asyncio.create_task(runner())
    try:
        while True:
            message = await queue.get()
            if message is sentinel:
                break
            if isinstance(message, str):
                yield message
    finally:
        if not worker.done():
            worker.cancel()
        with contextlib.suppress(asyncio.CancelledError):
            await worker


def build_ui() -> gr.Blocks:
    with gr.Blocks(title="Depression Agent UI") as demo:
        session_state = gr.State(_init_session())

        gr.Markdown("# æŠ‘éƒéšè®¿åŠ©æ‰‹")

        with gr.Tabs():
            with gr.Tab("è¯„ä¼°"):
                chatbot = gr.Chatbot(height=400, label="å¯¹è¯")
                text_input = gr.Textbox(label="æ‚£è€…è¾“å…¥", placeholder="è¯·è¾“å…¥æ–‡æœ¬")
                audio_input = gr.File(label="ä¸Šä¼ éŸ³é¢‘(16k mono)", type="filepath")
                audio_sys = gr.Audio(label="ç³»ç»Ÿè¯­éŸ³", interactive=False, autoplay=True)
                risk_alert = gr.Markdown("æ— ç´§æ€¥é£Žé™©æç¤ºã€‚")
                progress_display = gr.JSON(label="è¿›åº¦çŠ¶æ€")
                send_button = gr.Button("å‘é€")

            with gr.Tab("å®žæ—¶è¯†åˆ«"):
                gr.Markdown("## ðŸŽ§ å®žæ—¶è¯­éŸ³è¯†åˆ«")
                mic = gr.Audio(
                    sources=["microphone"],
                    type="numpy",
                    streaming=True,
                    label="ç‚¹å‡»å¼€å§‹å½•éŸ³ä»¥æŽ¨æµè‡³å¬æ‚Ÿ",
                )
                realtime_output = gr.Textbox(
                    label="å®žæ—¶è¯†åˆ«è¾“å‡º",
                    lines=8,
                    interactive=False,
                )
                mic.stream(
                    fn=realtime_stream_to_frontend,
                    inputs=mic,
                    outputs=realtime_output,
                )

            with gr.Tab("æŠ¥å‘Š"):
                gr.Markdown("## ç”Ÿæˆè¯„ä¼°æŠ¥å‘Š")
                gr.Markdown("ç‚¹å‡»æŒ‰é’®åŽå°†åœ¨ /tmp/depression_agent_reports/ ä¸‹ç”Ÿæˆ PDFã€‚")
                report_button = gr.Button("ç”ŸæˆæŠ¥å‘Š")
                report_status = gr.Markdown("ç­‰å¾…ç”ŸæˆæŒ‡ä»¤â€¦")

        def _on_submit(
            message: str,
            audio_path: Optional[str],
            history: List[Tuple[str, str]],
            session_id: str,
        ) -> Tuple[List[Tuple[str, str]], str, Optional[str], str, str, Dict[str, Any], Optional[str]]:
            chat, risk_text, progress, sid, audio_value = user_step(
                message, audio_path, history, session_id
            )
            return chat, "", None, sid, risk_text, progress, audio_value

        text_input.submit(
            _on_submit,
            inputs=[text_input, audio_input, chatbot, session_state],
            outputs=[
                chatbot,
                text_input,
                audio_input,
                session_state,
                risk_alert,
                progress_display,
                audio_sys,
            ],
        )

        send_button.click(
            _on_submit,
            inputs=[text_input, audio_input, chatbot, session_state],
            outputs=[
                chatbot,
                text_input,
                audio_input,
                session_state,
                risk_alert,
                progress_display,
                audio_sys,
            ],
        )

        report_button.click(
            lambda sid: _generate_report(sid),
            inputs=[session_state],
            outputs=[report_status],
        )

    return demo


if __name__ == "__main__":
    build_ui().launch(server_name="0.0.0.0", server_port=7860)
