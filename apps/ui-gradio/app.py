from __future__ import annotations

import asyncio
import contextlib
import json
import os
import queue
import ssl
import sys
import threading
import time
import uuid
from dataclasses import dataclass
from pathlib import Path
from typing import Any, AsyncGenerator, Callable, Dict, List, Optional, Tuple

PROJECT_ROOT = Path(__file__).resolve().parents[2]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))

import gradio as gr
import numpy as np
import requests
import websockets
import websockets.exceptions

from packages.common.config import settings
from services.audio.tingwu_async_client import (
    create_realtime_task,
    stop_realtime_task,
)

API_BASE = (
    os.getenv("DM_API_BASE", os.getenv("API_BASE_URL", "http://localhost:8080"))
    or "http://localhost:8080"
).rstrip("/")

DEFAULT_PROGRESS_TOTAL = 17

def _init_session() -> str:
    return str(uuid.uuid4())

def _call_dm_step(
    sid: str, text: Optional[str] = None, audio_ref: Optional[str] = None
) -> Dict[str, Any]:
    payload: Dict[str, Any] = {"sid": sid}
    if text:
        payload["text"] = text
    if audio_ref:
        payload["audio_ref"] = audio_ref

    response = requests.post(f"{API_BASE}/dm/step", json=payload, timeout=120)
    response.raise_for_status()
    return response.json()

def _generate_report(session_id: str) -> str:
    try:
        resp = requests.post(
            f"{API_BASE}/report/build", json={"sid": session_id}, timeout=60
        )
        resp.raise_for_status()
        data = resp.json()
        url = data.get("report_url")
        if url:
            return f"âœ… æŠ¥å‘Šå·²ç”Ÿæˆï¼š{url}"
        return "âš ï¸ æŠ¥å‘Šç”ŸæˆæˆåŠŸä½†æœªè¿”å›é“¾æ¥ã€‚"
    except Exception as exc:
        return f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼š{exc}"

def user_step(
    message: str,
    history: List[Tuple[Optional[str], str]],
    session_id: str,
) -> Tuple[List[Tuple[Optional[str], str]], str, Dict[str, Any], str, Optional[str]]:
    message = message or ""
    text_payload = message.strip() or None
    if not isinstance(history, list):
        history = []
    risk_text = "æ— ç´§æ€¥é£é™©æç¤ºã€‚"
    progress: Dict[str, Any] = {}
    media_value: Optional[str] = None

    try:
        result = _call_dm_step(session_id, text=text_payload, audio_ref=None)
    except Exception as exc:
        if text_payload:
            user_label = message
        else:
            user_label = "[ç©ºè¾“å…¥]"

        history = history + [(user_label, f"âŒ è¯·æ±‚å¤±è´¥ï¼š{exc}")]
        return history, "âš ï¸ è¯·æ±‚å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚", {}, session_id, None

    assistant_reply = result.get("next_utterance", "")
    previews = result.get("segments_previews") or []
    media_value = _extract_media_value(session_id, result)

    if previews:
        recent_previews = previews[-2:]
        preview_text = "\n".join(f"- {item}" for item in recent_previews if item)
        if preview_text:
            assistant_reply = f"{assistant_reply}\n\n_æœ€è¿‘è½¬å†™é¢„è§ˆ_:\n{preview_text}"

    user_label: Optional[str] = None
    if text_payload:
        user_label = message
    history = history + [(user_label or None, assistant_reply)]

    progress = result.get("progress", {})
    risk_flag = result.get("risk_flag", False)
    risk_text = (
        "âš ï¸ æ£€æµ‹åˆ°é«˜é£é™©ï¼Œè¯·ç«‹å³å¯»æ±‚ç´§æ€¥å¸®åŠ©ã€‚" if risk_flag else "æ— ç´§æ€¥é£é™©æç¤ºã€‚"
    )

    return history, risk_text, progress, session_id, media_value

def initialize_conversation(
    session_id: str,
) -> Tuple[List[Tuple[Optional[str], str]], str, str, Dict[str, Any], Optional[str]]:
    """ä¸ºæ–°ä¼šè¯é¢„æ‹‰å–é¦–ä¸ªé—®é¢˜ã€‚"""

    sid = session_id or _init_session()
    history: List[Tuple[Optional[str], str]] = []
    risk_text = "æ— ç´§æ€¥é£é™©æç¤ºã€‚"
    progress: Dict[str, Any] = {}

    try:
        result = _call_dm_step(sid)
    except Exception as exc:
        error_text = f"âŒ è¯·æ±‚å¤±è´¥ï¼š{exc}"
        history.append((None, error_text))
        return history, sid, "âš ï¸ åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚", {}, None

    assistant_reply = result.get("next_utterance", "")
    if assistant_reply:
        history.append((None, assistant_reply))

    progress = result.get("progress", {})
    risk_flag = result.get("risk_flag", False)
    risk_text = (
        "âš ï¸ æ£€æµ‹åˆ°é«˜é£é™©ï¼Œè¯·ç«‹å³å¯»æ±‚ç´§æ€¥å¸®åŠ©ã€‚" if risk_flag else "æ— ç´§æ€¥é£é™©æç¤ºã€‚"
    )

    media_value = _extract_media_value(sid, result)
    return history, sid, risk_text, progress, media_value

@dataclass(slots=True)
class TingwuStreamConfig:
    """å¬æ‚Ÿå®æ—¶æµé…ç½®"""
    appkey: str
    format: str = "pcm"
    language: str = "cn"
    sample_rate: int = 16000
    frame_ms: int = 20

class RealTimeTingwuClient:
    """ç®€åŒ–çš„å®æ—¶å¬æ‚Ÿå®¢æˆ·ç«¯"""
    
    def __init__(self, complete_sentence_callback: Optional[Callable[[str], None]] = None):
        self.config = self._build_config()
        self.ws = None
        self.task_id = None
        self.is_connected = False
        self.audio_queue = queue.Queue()
        self.result_queue = queue.Queue()
        self.complete_sentence_queue = queue.Queue()
        self.running = False
        self.complete_sentence_callback = complete_sentence_callback
        self.latest_result = "å‡†å¤‡å¼€å§‹..."
        
    def _build_config(self) -> TingwuStreamConfig:
        appkey = settings.TINGWU_APPKEY or settings.ALIBABA_TINGWU_APPKEY
        if not appkey:
            raise RuntimeError("è¯·åœ¨ .env ä¸­é…ç½® TINGWU_APPKEY")
            
        return TingwuStreamConfig(
            appkey=appkey,
            format=settings.TINGWU_FORMAT or "pcm",
            language=settings.TINGWU_LANG or "cn",
            sample_rate=16000,
        )
    
    def _ensure_mono(self, audio_data: np.ndarray) -> np.ndarray:
        if audio_data.ndim == 1:
            return audio_data
        return np.mean(audio_data, axis=1)
    
    def _resample_audio(self, audio_data: np.ndarray, original_sr: int, target_sr: int) -> np.ndarray:
        if original_sr == target_sr:
            return audio_data
        if audio_data.size == 0:
            return audio_data
            
        duration = len(audio_data) / original_sr
        target_length = int(duration * target_sr)
        if target_length == 0:
            return np.array([], dtype=np.float32)
            
        original_indices = np.arange(len(audio_data), dtype=np.float32)
        target_indices = np.linspace(0, len(audio_data)-1, target_length, dtype=np.float32)
        return np.interp(target_indices, original_indices, audio_data).astype(np.float32)
    
    def _audio_to_pcm(self, audio_data: np.ndarray) -> bytes:
        normalized = np.clip(audio_data, -1.0, 1.0)
        return (normalized * 32767).astype("<i2").tobytes()
    
    async def connect(self):
        """è¿æ¥åˆ°å¬æ‚ŸWebSocket"""
        try:
            ws_url, self.task_id = await create_realtime_task()
            
            connect_kwargs = {
                "ping_interval": 10,
                "ping_timeout": 30,
                "max_size": 10 * 1024 * 1024,
            }
            
            try:
                self.ws = await websockets.connect(ws_url, **connect_kwargs)
            except Exception as e:
                if "SSL" in str(e) or "302" in str(e):
                    connect_kwargs["ssl"] = ssl._create_unverified_context()
                    self.ws = await websockets.connect(ws_url, **connect_kwargs)
                else:
                    raise
            
            self.is_connected = True
            
            start_message = {
                "header": {
                    "namespace": "SpeechTranscriber",
                    "name": "StartTranscription",
                    "task_id": self.task_id,
                },
                "payload": {
                    "format": self.config.format,
                    "sample_rate": self.config.sample_rate,
                    "enable_chinese_english_translation": False,
                    "enable_speech_detection": True,
                    "enable_words": False,
                    "enable_intermediate_result": True,
                    "enable_punctuation_prediction": True,
                    "enable_inverse_text_normalization": True,
                    "enable_semantic_sentence_detection": True,
                    "max_sentence_silence": 800,
                },
            }
            
            await self.ws.send(json.dumps(start_message, ensure_ascii=False))
            return True
            
        except Exception as e:
            self.result_queue.put(f"âŒ è¿æ¥å¤±è´¥: {e}")
            return False
    
    async def send_audio_chunk(self, audio_chunk: np.ndarray, sample_rate: int):
        if not self.is_connected or not self.ws:
            return
        
        try:
            mono_audio = self._ensure_mono(audio_chunk.astype(np.float32))
            processed_audio = self._resample_audio(mono_audio, sample_rate, self.config.sample_rate)
            
            if processed_audio.size == 0:
                return
                
            pcm_data = self._audio_to_pcm(processed_audio)
            await self.ws.send(pcm_data)
                
        except Exception as e:
            print(f"âš ï¸ å‘é€éŸ³é¢‘å¤±è´¥: {e}")
    
    async def receive_messages(self):
        if not self.is_connected or not self.ws:
            return
            
        try:
            async for message in self.ws:
                if not self.running:
                    break
                    
                if isinstance(message, bytes):
                    continue
                    
                try:
                    data = json.loads(message)
                except json.JSONDecodeError:
                    continue
                
                await self._handle_message(data)
                
        except websockets.exceptions.ConnectionClosed:
            if self.running:
                self.result_queue.put("âš ï¸ è¿æ¥ä¸­æ–­")
        except Exception as e:
            if self.running:
                self.result_queue.put(f"âš ï¸ è¿æ¥é”™è¯¯: {e}")
    
    def _extract_text_from_payload(self, payload: dict) -> Optional[str]:
        if not isinstance(payload, dict):
            return None
            
        text_fields = ["result", "text", "transcript", "asr_text"]
        for field in text_fields:
            value = payload.get(field)
            if isinstance(value, str) and value.strip():
                return value.strip()
        
        words = payload.get("words")
        if isinstance(words, list):
            word_texts = []
            for word in words:
                if isinstance(word, dict) and word.get("text"):
                    word_texts.append(word["text"])
            if word_texts:
                return " ".join(word_texts)
                
        return None
    
    async def _handle_message(self, data: dict):
        header = data.get("header", {})
        payload = data.get("payload", {})
        name = header.get("name")
        
        if name == "TranscriptionStarted":
            self.latest_result = "ğŸ¤ å®æ—¶è½¬å½•å·²å¼€å§‹ï¼Œè¯·è¯´è¯..."
            self.result_queue.put(self.latest_result)
            
        elif name in ["TranscriptionResult", "TranscriptionResultChanged"]:
            result_text = self._extract_text_from_payload(payload)
            if result_text:
                self.latest_result = f"ğŸ“ {result_text}"
                self.result_queue.put(self.latest_result)
                
        elif name == "SentenceEnd":
            result_text = self._extract_text_from_payload(payload)
            if result_text:
                self.complete_sentence_queue.put(result_text)
                if self.complete_sentence_callback:
                    self.complete_sentence_callback(result_text)
                
                self.latest_result = f"âœ… å®Œæ•´å¥å­: {result_text}"
                self.result_queue.put(self.latest_result)
            
        elif name == "TaskFailed":
            error_msg = payload.get("message", payload.get("error_message", "ä»»åŠ¡æ‰§è¡Œå¤±è´¥"))
            detailed_error = f"âŒ ä»»åŠ¡å¤±è´¥: {error_msg}"
            self.latest_result = detailed_error
            self.result_queue.put(detailed_error)
            self.running = False
    
    async def start_realtime_stream(self):
        """å¼€å§‹å®æ—¶æµå¼å¤„ç†"""
        self.running = True
        
        if not await self.connect():
            self.running = False
            return
        
        receive_task = asyncio.create_task(self.receive_messages())
        
        try:
            while self.running:
                try:
                    audio_data = self.audio_queue.get_nowait()
                    sample_rate, audio_chunk = audio_data
                    
                    if audio_chunk.size > 0:
                        await self.send_audio_chunk(audio_chunk, sample_rate)
                    
                except queue.Empty:
                    await asyncio.sleep(0.01)
                except Exception as e:
                    print(f"âš ï¸ å¤„ç†éŸ³é¢‘æ•°æ®é”™è¯¯: {e}")
                    await asyncio.sleep(0.01)
                    
        except Exception as e:
            self.result_queue.put(f"âŒ å®æ—¶æµé”™è¯¯: {e}")
        finally:
            self.running = False
            if not receive_task.done():
                receive_task.cancel()
            
            with contextlib.suppress(asyncio.CancelledError):
                if not receive_task.done():
                    await receive_task
            
            await self.close()
    
    def add_audio_data(self, sample_rate: int, audio_data: np.ndarray):
        if self.running and audio_data is not None and audio_data.size > 0:
            self.audio_queue.put((sample_rate, audio_data))
    
    def get_latest_result(self) -> str:
        return self.latest_result
    
    def get_results(self):
        results = []
        while not self.result_queue.empty():
            try:
                results.append(self.result_queue.get_nowait())
            except queue.Empty:
                break
        return results
    
    def get_complete_sentences(self) -> List[str]:
        sentences = []
        while not self.complete_sentence_queue.empty():
            try:
                sentences.append(self.complete_sentence_queue.get_nowait())
            except queue.Empty:
                break
        return sentences
    
    async def close(self):
        self.running = False
        
        if self.is_connected and self.ws:
            try:
                stop_message = {
                    "header": {
                        "namespace": "SpeechTranscriber", 
                        "name": "StopTranscription"
                    },
                    "payload": {}
                }
                await self.ws.send(json.dumps(stop_message, ensure_ascii=False))
                await asyncio.sleep(1)
            except Exception:
                pass
            finally:
                try:
                    await self.ws.close()
                except Exception:
                    pass
                self.is_connected = False

# å…¨å±€å®¢æˆ·ç«¯å®ä¾‹å’ŒçŠ¶æ€ç®¡ç†
_client: Optional[RealTimeTingwuClient] = None
_client_lock = threading.Lock()
_complete_sentences: List[str] = []
_transcription_active = False

def handle_complete_sentence(sentence: str) -> None:
    global _complete_sentences
    _complete_sentences.append(sentence)

def get_latest_complete_sentence() -> Optional[str]:
    global _complete_sentences
    if _complete_sentences:
        return _complete_sentences[-1]
    return None

def get_all_complete_sentences() -> List[str]:
    global _complete_sentences
    return _complete_sentences.copy()

def clear_complete_sentences() -> None:
    global _complete_sentences
    _complete_sentences.clear()

def _format_sentences_display(sentences: List[str]) -> str:
    if not sentences:
        return "æš‚æ— å®Œæ•´å¥å­"
    return "\n\n".join(f"{index + 1}. {value}" for index, value in enumerate(sentences))

def _ensure_audio_playable_url(session_id: str, audio_value: Optional[str]) -> Optional[str]:
    if not audio_value:
        return None
    if isinstance(audio_value, str) and audio_value.startswith(("http://", "https://")):
        return audio_value
    local_path = audio_value
    if isinstance(local_path, str) and local_path.startswith("file://"):
        local_path = local_path[7:]
    if not local_path or not Path(local_path).exists():
        return audio_value
    return str(Path(local_path).resolve())

def _extract_media_value(session_id: str, result: Dict[str, Any]) -> Optional[str]:
    if not result:
        return None

    media_type = (result.get("media_type") or "").lower()
    if media_type == "video":
        return result.get("video_url")

    if media_type == "audio":
        return _ensure_audio_playable_url(session_id, result.get("tts_url"))

    return None

# åˆ›å»ºå…¨å±€äº‹ä»¶å¾ªç¯å’Œä»»åŠ¡ç®¡ç†
_event_loop = None
_background_tasks = set()

def get_or_create_event_loop():
    global _event_loop
    if _event_loop is None:
        _event_loop = asyncio.new_event_loop()
        def run_loop():
            asyncio.set_event_loop(_event_loop)
            _event_loop.run_forever()
        
        thread = threading.Thread(target=run_loop, daemon=True)
        thread.start()
    return _event_loop

def run_async_in_background(coro):
    loop = get_or_create_event_loop()
    task = asyncio.run_coroutine_threadsafe(coro, loop)
    _background_tasks.add(task)
    task.add_done_callback(_background_tasks.discard)
    return task

async def start_realtime_transcription():
    global _client, _transcription_active
    
    with _client_lock:
        if _client is None or not _client.running:
            _client = RealTimeTingwuClient(complete_sentence_callback=handle_complete_sentence)
    
    if _client:
        _transcription_active = True
        run_async_in_background(_client.start_realtime_stream())
        return "ğŸ”„ æ­£åœ¨å¯åŠ¨å®æ—¶è½¬å½•..."
    
    return "âŒ æ— æ³•å¯åŠ¨å®¢æˆ·ç«¯"

async def stop_transcription() -> str:
    global _client, _transcription_active
    
    _transcription_active = False
    
    with _client_lock:
        client = _client
        _client = None
    
    if client is not None:
        await client.close()
    
    clear_complete_sentences()
    return "ğŸ›‘ è½¬å½•å·²åœæ­¢"

def get_realtime_status() -> str:
    global _client
    with _client_lock:
        if _client is not None and _client.running:
            return _client.get_latest_result()
    return "å®æ—¶è½¬å½•æœªå¯åŠ¨"

def get_current_sentences() -> Tuple[str, str]:
    latest = get_latest_complete_sentence() or "æš‚æ— å®Œæ•´å¥å­"
    all_sentences = _format_sentences_display(get_all_complete_sentences())
    return latest, all_sentences

def start_transcription_sync():
    try:
        run_async_in_background(start_realtime_transcription())
        return "ğŸ”„ æ­£åœ¨å¯åŠ¨å®æ—¶è½¬å½•..."
    except Exception as e:
        return f"âŒ å¯åŠ¨å¤±è´¥: {e}"

def stop_transcription_sync():
    try:
        run_async_in_background(stop_transcription())
        return "ğŸ›‘ æ­£åœ¨åœæ­¢è½¬å½•..."
    except Exception as e:
        return f"âŒ åœæ­¢å¤±è´¥: {e}"

def handle_audio_input(audio: Optional[Tuple[int, np.ndarray]]) -> str:
    global _client
    
    if audio is None:
        return get_realtime_status()
    
    try:
        sample_rate, audio_data = audio
        
        if audio_data is None or audio_data.size == 0:
            return "æœªæ£€æµ‹åˆ°æœ‰æ•ˆéŸ³é¢‘æ•°æ®"
        
        with _client_lock:
            if _client is not None and _client.running:
                _client.add_audio_data(sample_rate, audio_data)
                return _client.get_latest_result()
            else:
                return "è¯·å…ˆç‚¹å‡»'å¼€å§‹å½•éŸ³'æŒ‰é’®å¯åŠ¨è¯­éŸ³è¯†åˆ«"
                
    except Exception as e:
        return f"âŒ å¤„ç†é”™è¯¯: {e}"

def poll_realtime_status():
    return get_realtime_status()

def poll_sentences():
    return get_current_sentences()

def _coerce_int(value: Any) -> int:
    if isinstance(value, bool):
        return int(value)
    if isinstance(value, (int, float)):
        return int(value)
    if isinstance(value, str):
        try:
            return int(float(value))
        except ValueError:
            return 0
    return 0

def _format_progress_heading(progress: Optional[Dict[str, Any]]) -> str:
    data = progress or {}

    index = 0
    total = 0

    if "index" in data or "total" in data:
        index = _coerce_int(data.get("index"))
        total = _coerce_int(data.get("total"))

    if total <= 0 and ("current_step" in data or "total_steps" in data):
        index = _coerce_int(data.get("current_step"))
        total = _coerce_int(data.get("total_steps"))

    if total <= 0:
        total = DEFAULT_PROGRESS_TOTAL

    if index < 0:
        index = 0
    if total > 0 and index > total:
        index = total

    pct = _get_progress_value(data)
    if pct <= 0 and total > 0 and index > 0:
        pct = (index / total) * 100.0

    pct = max(0.0, min(100.0, pct))

    return f"### ğŸ§  ä¸“ä¸šè¯„ä¼°è¿›åº¦ï¼ˆ{index}/{total} Â· {pct:.0f}%ï¼‰"

def _get_progress_value(progress: Dict[str, Any]) -> float:
    if not progress:
        return 0.0
    
    if "index" in progress and "total" in progress:
        index = progress["index"]
        total = progress["total"]
        if total > 0:
            return (index / total) * 100.0
    
    if "overall" in progress:
        value = progress["overall"]
        if isinstance(value, (int, float)):
            return float(value)
    
    if "progress" in progress:
        value = progress["progress"]
        if isinstance(value, (int, float)):
            return float(value)
    
    if "percentage" in progress:
        value = progress["percentage"]
        if isinstance(value, (int, float)):
            return float(value)
    
    if "current_step" in progress and "total_steps" in progress:
        current = progress["current_step"]
        total = progress["total_steps"]
        if total > 0:
            return (current / total) * 100.0
    
    return 0.0

def build_ui() -> gr.Blocks:
    with gr.Blocks(
        theme=gr.themes.Soft(primary_hue="blue", secondary_hue="slate"),
        title="æ™ºèƒ½å¿ƒå¢ƒå¥åº·è¯„ä¼°ç³»ç»Ÿ",
        css="""
        .gradio-container {
            max-width: 100% !important;
            width: 100% !important;
            background-image: url("https://bpic.588ku.com/back_pic/06/42/63/94647d8c29b3127.jpg") !important;
            background-color: #e8f4f8 !important;
            background-repeat: no-repeat !important;
            background-position: center center !important;
            background-size: cover !important;
            background-attachment: fixed !important;
            min-height: 100vh !important;
        }
        .risk-alert {
            padding: 12px;
            border-radius: 8px;
            margin: 8px 0;
            font-weight: bold;
        }
        .risk-high {
            background: linear-gradient(135deg, #ff6b6b 0%, #ee5a24 100%);
            color: white;
            border: 2px solid #ff3838;
        }
        .risk-low {
            background: linear-gradient(135deg, #4ecdc4 0%, #44a08d 100%);
            color: white;
            border: 2px solid #00b894;
        }
        .section-title {
            background: linear-gradient(90deg, #667eea, #764ba2);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            font-weight: 800;
            font-size: 1.3em;
            margin-bottom: 12px;
        }
        .progress-title {
            text-align: center;
            margin: 8px 0 16px;
            font-weight: 700;
            color: #374151;
        }
        .gr-button {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
            color: white !important;
            border: none !important;
        }
        .gr-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(102, 126, 234, 0.4);
        }
        .transparent-markdown {
            background: transparent !important;
            backdrop-filter: none !important;
            -webkit-backdrop-filter: none !important;
            border: none !important;
            box-shadow: none !important;
        }
        .title-container {
            background: transparent !important;
            backdrop-filter: none !important;
            -webkit-backdrop-filter: none !important;
            border: none !important;
            box-shadow: none !important;
            padding: 20px !important;
            margin-bottom: 20px !important;
        }

        #video_sys,
        #chatbot,
        #patient_input,
        #realtime_status,
        #audio_capture,
        #latest_sentence,
        #all_sentences{
            border: 1.5px solid #cbd5e1 !important;
            border-radius: 10px !important;
            background: rgba(255, 255, 255, 0.96) !important;
            box-shadow: 0 3px 10px rgba(0, 0, 0, 0.12) !important;
        }
        
        #video_sys {
            width: 238px !important;
            height: 420px !important;
            overflow: hidden !important;
        }

        #video_sys video {
            width: 100% !important;
            height: 100% !important;
            object-fit: cover !important;
            border-radius: 10px;
        }

        #chatbot {
            height: 420px !important;
        }

        .gradio-container .gr-row {
            max-width: 1200px !important;
            margin: 0 auto !important;
        }
        """
    ) as demo:
        session_state = gr.State(_init_session())
        last_video_state = gr.State(None)
        
        gr.Markdown(
            """
            <div class="title-container">
                <div style="text-align: center; padding: 10px 0;">
                    <h1 style="
                        background: linear-gradient(135deg, #20e3b2 0%, #0f3d5e 100%);
                        -webkit-background-clip: text;
                        -webkit-text-fill-color: transparent;
                        font-weight: 800;
                        font-size: 3em;
                        margin-bottom: 8px;
                    ">
                        ğŸ§  æ™ºèƒ½å¿ƒå¢ƒå¥åº·è¯„ä¼°ç³»ç»Ÿ
                    </h1>
                    <p style="
                        color: #666;
                        font-size: 1.1em;
                        margin-bottom: 15px;
                        font-weight: 500;
                    ">
                        èåˆå¤šæ¨¡æ€äº¤äº’çš„ç²¾å‡†å¿ƒç†å¥åº·ç­›æŸ¥ä¸æ™ºèƒ½éšè®¿å¹³å°
                    </p>
                </div>
            </div>
            """,
            elem_classes=["transparent-markdown"],
        )

        with gr.Tabs():
            with gr.Tab("ğŸ¥ ä¸“ä¸šè¯„ä¼°"):
                with gr.Row(equal_height=True):
                    with gr.Column(scale=7, min_width=600):
                        gr.Markdown(
                            """
                            <div class="section-title">ğŸ’¡ ä¸“ä¸šæç¤º</div>
                            <ul style="margin:8px 0 0 18px; font-weight:700;line-height:1.6;">
                              <li>è¯·å°½å¯èƒ½è¯¦ç»†æè¿°æ‚¨çš„çœŸå®æ„Ÿå—</li>
                              <li>ç³»ç»Ÿä¼šä¸¥æ ¼ä¿å¯†æ‚¨çš„æ‰€æœ‰ä¿¡æ¯</li>
                              <li>å¦‚éœ€ç´§æ€¥å¸®åŠ©ï¼Œè¯·ç«‹å³è”ç³»ä¸“ä¸šåŒ»ç”Ÿ</li>
                            </ul>
                            """,
                            elem_classes=["transparent-markdown"],
                        )

                        progress_title = gr.Markdown(
                            _format_progress_heading(None),
                            elem_classes=["progress-title", "transparent-markdown"],
                        )

                        with gr.Row(equal_height=True):
                            with gr.Column(scale=3, min_width=240):
                                video_sys = gr.Video(
                                    label="æ•°å­—äººäº¤äº’",
                                    interactive=False,
                                    autoplay=True,
                                    elem_id="video_sys",
                                    height=420,
                                )

                            with gr.Column(scale=7, min_width=600):
                                chatbot = gr.Chatbot(
                                    height=420,
                                    label="æ™ºèƒ½å¯¹è¯è®°å½•",
                                    show_copy_button=True,
                                    elem_id="chatbot",
                                )

                        risk_alert = gr.Markdown(
                            """
                            <div class="risk-alert risk-low">
                                âœ… å½“å‰çŠ¶æ€ï¼šæ— ç´§æ€¥é£é™©æç¤º
                            </div>
                            """,
                            elem_classes=["transparent-markdown"],
                        )

                        text_input = gr.Textbox(
                            label="æ‚£è€…è‡ªè¿°è¾“å…¥",
                            placeholder="è¯·è¯¦ç»†æè¿°æ‚¨è¿‘æœŸçš„æƒ…ç»ªçŠ¶æ€ã€ç¡çœ è´¨é‡ã€ç”Ÿæ´»å‹åŠ›ç­‰æƒ…å†µ...",
                            lines=4,
                            max_lines=6,
                            show_copy_button=True,
                            elem_id="patient_input",
                        )

                        with gr.Row():
                            send_button = gr.Button("ğŸ“¤ æäº¤è¯„ä¼°", variant="primary", size="lg")
                            clear_chat_btn = gr.Button("ğŸ”„ é‡æ–°å¼€å§‹", variant="secondary")

                    with gr.Column(scale=4, min_width=400):
                        gr.Markdown(
                            """
                            <div class="section-title">ğŸ¯ è¯­éŸ³ä½¿ç”¨æŒ‡å—</div>
                            <ol style="margin:8px 0 0 18px; font-weight:700;line-height:1.6;">
                              <li>ç‚¹å‡» <b>å¼€å§‹è¯­éŸ³è¾“å…¥</b> å¯åŠ¨è¯­éŸ³è¯†åˆ«</li>
                              <li>ç”¨è‡ªç„¶è¯­è¨€æè¿°æ‚¨çš„æƒ…å†µ</li>
                              <li>è¯†åˆ«ç»“æœä¼šå®æ—¶æ˜¾ç¤ºï¼Œå®Œæ•´å¥å­ä¼šè‡ªåŠ¨æ±‡æ€»</li>
                              <li>éœ€è¦æ—¶ç‚¹å‡» <b>åœæ­¢å½•éŸ³</b> ç»“æŸè¯­éŸ³è¾“å…¥</li>
                            </ol>
                            """,
                            elem_classes=["transparent-markdown"],
                        )

                        gr.Markdown(
                            """
                            <div class="section-title">
                                ğŸ¤ æ™ºèƒ½è¯­éŸ³è¯†åˆ«
                            </div>
                            """,
                            elem_classes=["transparent-markdown"],
                        )
                        
                        with gr.Row():
                            start_mic_btn = gr.Button(
                                "ğŸ™ï¸ å¼€å§‹è¯­éŸ³è¾“å…¥", 
                                variant="primary",
                                size="lg"
                            )
                            stop_mic_btn = gr.Button(
                                "â¹ï¸ åœæ­¢å½•éŸ³", 
                                variant="stop"
                            )
                        
                        realtime_output = gr.Textbox(
                            label="å®æ—¶è½¬å½•çŠ¶æ€",
                            lines=3,
                            show_copy_button=True,
                            interactive=False,
                            value="ç‚¹å‡»ä¸Šæ–¹æŒ‰é’®å¼€å§‹è¯­éŸ³è¾“å…¥",
                            placeholder="è¯­éŸ³è¯†åˆ«ç»“æœå°†å®æ—¶æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                            elem_id="realtime_status",
                        )

                        audio_input = gr.Audio(
                            sources=["microphone"],
                            type="numpy",
                            streaming=True,
                            label="å®æ—¶éŸ³é¢‘é‡‡é›†",
                            elem_id="audio_capture",
                        )

                        with gr.Accordion("ğŸ“ è¯­éŸ³è¯†åˆ«ç»“æœ", open=True):
                            latest_sentence = gr.Textbox(
                                label="æœ€æ–°è¯†åˆ«å†…å®¹",
                                lines=2,
                                interactive=False,
                                placeholder="å®Œæ•´å¥å­å°†è‡ªåŠ¨æ˜¾ç¤ºåœ¨è¿™é‡Œ...",
                                show_copy_button=True,
                                elem_id="latest_sentence",
                            )
                            all_sentences = gr.Textbox(
                                label="å†å²è¯†åˆ«è®°å½•",
                                lines=3,
                                interactive=False,
                                placeholder="æ‰€æœ‰è¯†åˆ«ç»“æœå°†æ±‡æ€»åœ¨è¿™é‡Œ...",
                                show_copy_button=True,
                                elem_id="all_sentences",
                            )
                            with gr.Row():
                                submit_sentence_btn = gr.Button(
                                    "ğŸš€ æäº¤æ­¤å†…å®¹", 
                                    variant="primary",
                                    size="sm"
                                )
                                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°", size="sm")
                                clear_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•", size="sm")
                        
            with gr.Tab("ğŸ“Š è¯„ä¼°æŠ¥å‘Š"):
                gr.Markdown(
                    """
                    <div class="section-title">
                        ğŸ“ˆ ä¸“ä¸šè¯„ä¼°æŠ¥å‘Š
                    </div>
                    """,
                    elem_classes=["transparent-markdown"],
                )
                gr.Markdown(
                    """
                    **ç³»ç»Ÿå°†åŸºäºå¯¹è¯å†…å®¹ç”Ÿæˆä¸“ä¸šè¯„ä¼°æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š**
                    - ğŸ“‹ ç»¼åˆå¿ƒç†çŠ¶æ€åˆ†æ
                    - ğŸ“Š é£é™©è¯„ä¼°ç­‰çº§
                    - ğŸ’¡ ä¸ªæ€§åŒ–å»ºè®®æ–¹æ¡ˆ
                    - ğŸ¥ ä¸“ä¸šè½¬è¯ŠæŒ‡å¼•
                    """,
                    elem_classes=["transparent-markdown"],
                )
                with gr.Row():
                    report_button = gr.Button("ç”Ÿæˆä¸“ä¸šæŠ¥å‘Š", variant="primary", size="lg")
                report_status = gr.Markdown("ç­‰å¾…ç”ŸæˆæŒ‡ä»¤â€¦")

        # ä¿®æ”¹æ–‡æœ¬è¾“å…¥å¤„ç†å‡½æ•° - ä¿®å¤è§†é¢‘é—ªå±é—®é¢˜
        def _on_submit(
            message: str,
            last_video: Optional[str],
            history: List[Tuple[Optional[str], str]],
            session_id: str,
        ) -> Tuple[
            List[Tuple[Optional[str], str]],
            str,
            str,
            str,
            Optional[str],
            Optional[str],
            gr.update,
        ]:
            chat, risk_text, progress, sid, media_value = user_step(
                message, history, session_id
            )

            progress_text = _format_progress_heading(progress)

            if "é«˜é£é™©" in risk_text:
                risk_display = f"""
                <div class="risk-alert risk-high">
                    âš ï¸ {risk_text}
                </div>
                """
            else:
                risk_display = f"""
                <div class="risk-alert risk-low">
                    âœ… {risk_text}
                </div>
                """
            
            # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šå§‹ç»ˆä¿ç•™ä¸Šä¸€ä¸ªè§†é¢‘ï¼Œé™¤éæœ‰æ˜ç¡®çš„æ–°è§†é¢‘
            if media_value is None:
                # æ²¡æœ‰æ–°è§†é¢‘æ—¶ï¼Œä¿æŒæ˜¾ç¤ºä¸Šä¸€ä¸ªè§†é¢‘
                media_value = last_video
            else:
                # æœ‰æ–°è§†é¢‘æ—¶ï¼Œæ›´æ–°çŠ¶æ€
                last_video = media_value
            
            # ç¡®ä¿ media_value æ˜¯å­—ç¬¦ä¸²ç±»å‹
            if not isinstance(media_value, (str, type(None))):
                media_value = None
                
            return (
                chat,
                "",
                sid,
                risk_display,
                media_value,
                last_video,
                gr.update(value=progress_text),
            )

        text_input.submit(
            _on_submit,
            inputs=[text_input, last_video_state, chatbot, session_state],
            outputs=[
                chatbot,
                text_input,
                session_state,
                risk_alert,
                video_sys,
                last_video_state,
                progress_title,
            ],
        )

        send_button.click(
            _on_submit,
            inputs=[text_input, last_video_state, chatbot, session_state],
            outputs=[
                chatbot,
                text_input,
                session_state,
                risk_alert,
                video_sys,
                last_video_state,
                progress_title,
            ],
        )

        # ä¿®æ”¹æ¸…ç©ºå¯¹è¯å‡½æ•°
        def clear_chat():
            new_session = _init_session()
            return (
                [],
                new_session,
                """
            <div class="risk-alert risk-low">
                âœ… å½“å‰çŠ¶æ€ï¼šæ— ç´§æ€¥é£é™©æç¤º
            </div>
            """,
                None,
                None,
                gr.update(value=_format_progress_heading(None)),
            )

        clear_chat_btn.click(
            fn=clear_chat,
            outputs=[chatbot, session_state, risk_alert, video_sys, last_video_state, progress_title]
        )

        # å®æ—¶è¯­éŸ³è¯†åˆ«æ§åˆ¶
        start_mic_btn.click(
            fn=start_transcription_sync,
            outputs=[realtime_output]
        )

        stop_mic_btn.click(
            fn=stop_transcription_sync,
            outputs=[realtime_output]
        )

        # éŸ³é¢‘è¾“å…¥å¤„ç†
        audio_input.stream(
            fn=handle_audio_input,
            inputs=[audio_input],
            outputs=[realtime_output],
            show_progress="hidden"
        )

        # åˆ·æ–°å¥å­
        refresh_btn.click(
            fn=poll_sentences,
            outputs=[latest_sentence, all_sentences]
        )

        # æ¸…ç©ºå¥å­
        def clear_sentences_action() -> Tuple[str, str]:
            clear_complete_sentences()
            return "å·²æ¸…ç©ºè®°å½•", "å·²æ¸…ç©ºè®°å½•"

        clear_btn.click(
            fn=clear_sentences_action,
            outputs=[latest_sentence, all_sentences],
        )

        # ä¿®æ”¹æäº¤å¥å­å‡½æ•° - ä¿®å¤è§†é¢‘é—ªå±é—®é¢˜
        def submit_current_sentence_sync(
            history: List[Tuple[Optional[str], str]],
            session_id: str,
            last_video: Optional[str],
        ) -> Tuple[
            List[Tuple[Optional[str], str]],
            str,
            str,
            Optional[str],
            Optional[str],
            str,
            str,
            gr.update,
        ]:
            current_sentence = get_latest_complete_sentence()
            if not current_sentence or current_sentence == "æš‚æ— å®Œæ•´å¥å­":
                latest, all_sents = get_current_sentences()
                return (
                    history,
                    """
                <div class="risk-alert risk-low">
                    âœ… å½“å‰çŠ¶æ€ï¼šæ— ç´§æ€¥é£é™©æç¤º
                </div>
                """,
                    session_id,
                    None,
                    last_video,
                    latest,
                    all_sents,
                    gr.update(),
                )

            updated_history, risk_text, progress, updated_session, media_value = user_step(
                current_sentence, history, session_id
            )

            progress_text = _format_progress_heading(progress)

            if "é«˜é£é™©" in risk_text:
                risk_display = f"""
                <div class="risk-alert risk-high">
                    âš ï¸ {risk_text}
                </div>
                """
            else:
                risk_display = f"""
                <div class="risk-alert risk-low">
                    âœ… {risk_text}
                </div>
                """
            
            # ğŸ¯ å…³é”®ä¿®æ”¹ï¼šå§‹ç»ˆä¿ç•™ä¸Šä¸€ä¸ªè§†é¢‘ï¼Œé™¤éæœ‰æ˜ç¡®çš„æ–°è§†é¢‘
            if media_value is None:
                # æ²¡æœ‰æ–°è§†é¢‘æ—¶ï¼Œä¿æŒæ˜¾ç¤ºä¸Šä¸€ä¸ªè§†é¢‘
                media_value = last_video
            else:
                # æœ‰æ–°è§†é¢‘æ—¶ï¼Œæ›´æ–°çŠ¶æ€
                last_video = media_value
            
            latest, all_sents = get_current_sentences()

            return (
                updated_history,
                risk_display,
                updated_session,
                media_value,
                last_video,
                latest,
                all_sents,
                gr.update(value=progress_text),
            )

        submit_sentence_btn.click(
            fn=submit_current_sentence_sync,
            inputs=[chatbot, session_state, last_video_state],
            outputs=[
                chatbot,
                risk_alert,
                session_state,
                video_sys,
                last_video_state,
                latest_sentence,
                all_sentences,
                progress_title,
            ]
        )

        report_button.click(
            lambda sid: _generate_report(sid),
            inputs=[session_state],
            outputs=[report_status],
        )

        # ä¿®æ”¹åˆå§‹åŒ–å¯¹è¯å‡½æ•° - ä¿®å¤è§†é¢‘é—ªå±é—®é¢˜
        def initialize_with_progress(session_id: str):
            history, sid, risk_text, progress, media_value = initialize_conversation(session_id)

            progress_text = _format_progress_heading(progress)

            if "é«˜é£é™©" in risk_text:
                risk_display = f"""
                <div class="risk-alert risk-high">
                    âš ï¸ {risk_text}
                </div>
                """
            else:
                risk_display = f"""
                <div class="risk-alert risk-low">
                    âœ… {risk_text}
                </div>
                """

            return (
                history,
                sid,
                risk_display,
                media_value,
                media_value,  # åŒæ—¶è®¾ç½® last_video_state
                gr.update(value=progress_text),
            )

        demo.load(
            fn=initialize_with_progress,
            inputs=[session_state],
            outputs=[chatbot, session_state, risk_alert, video_sys, last_video_state, progress_title],
        )

        # æ·»åŠ è½®è¯¢ç»„ä»¶
        with gr.Row(visible=False) as poll_row:
            status_poll_trigger = gr.Button("æ›´æ–°çŠ¶æ€", elem_id="status_poll")
            sentences_poll_trigger = gr.Button("æ›´æ–°å¥å­", elem_id="sentences_poll")

        # çŠ¶æ€è½®è¯¢
        status_poll_trigger.click(
            fn=poll_realtime_status,
            outputs=[realtime_output]
        )

        # å¥å­è½®è¯¢
        sentences_poll_trigger.click(
            fn=poll_sentences,
            outputs=[latest_sentence, all_sentences]
        )

        # ç®€åŒ–çš„JavaScript - åªå¤„ç†è½®è¯¢
        demo.load(
            None,
            None,
            None,
            js="""
            // çŠ¶æ€è½®è¯¢ - æ¯ç§’æ›´æ–°ä¸€æ¬¡
            setInterval(() => {
                const statusBtn = document.getElementById('status_poll');
                if (statusBtn) statusBtn.click();
            }, 1000);

            // å¥å­è½®è¯¢ - æ¯2ç§’æ›´æ–°ä¸€æ¬¡
            setInterval(() => {
                const sentencesBtn = document.getElementById('sentences_poll');
                if (sentencesBtn) sentencesBtn.click();
            }, 2000);
            """
        )

    return demo

def main():
    """ç›´æ¥å¯åŠ¨Gradioåº”ç”¨ï¼ˆç‹¬ç«‹è¿è¡Œï¼‰"""
    print("ğŸš€ å¯åŠ¨æ™ºèƒ½å¿ƒå¢ƒå¥åº·è¯„ä¼°ç³»ç»Ÿ...")
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
    print(f"ğŸ”‘ å¬æ‚Ÿ AppKey: {settings.TINGWU_APPKEY or settings.ALIBABA_TINGWU_APPKEY or 'æœªé…ç½®'}")
    
    demo = build_ui()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        share=False
    )

if __name__ == "__main__":
    main()